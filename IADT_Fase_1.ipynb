{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Este projeto foi desenvolvido como parte do desafio do **IADT ‚Äî Fase 1**. O objetivo √© desenvolver modelos preditivos para estimar os **custos m√©dicos individuais** cobrados por seguros de sa√∫de, com base em atributos como:\n",
    "\n",
    "- Idade\n",
    "- √çndice de massa corporal (IMC)\n",
    "- N√∫mero de filhos\n",
    "- Tabagismo\n",
    "- Sexo\n",
    "- Regi√£o geogr√°fica\n",
    "\n",
    "Trata-se de um problema de **regress√£o supervisionada**, com vari√°vel alvo cont√≠nua (custos m√©dicos), abordado com modelos lineares e baseados em √°rvores de decis√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonte de Dados\n",
    "\n",
    "O conjunto de dados foi obtido na plataforma **Kaggle**, dispon√≠vel no reposit√≥rio [\"Healthcare Insurance\"](https://www.kaggle.com/datasets/willianoliveiragibin/healthcare-insurance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Utilizados\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "- Gradient Boosting Regressor\n",
    "- Ordinary Least Squares (OLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFhYZw3y2ATa"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instala√ß√£o de Depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqJQKDRgppBt",
    "outputId": "0075a0a4-dcb3-4dc2-c75c-7c5b675e0818"
   },
   "outputs": [],
   "source": [
    "# Instala√ß√£o das bibliotecas necess√°rias para o projeto\n",
    "! pip install --quiet pandas numpy matplotlib seaborn scikit-learn statsmodels kagglehub joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipula√ß√£o de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelagem\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Pr√©-processamento\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Valida√ß√£o e avalia√ß√£o\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Estat√≠stica\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# KaggleHub (carregamento de dataset)\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Salvamento e carregamento de modelos treinados\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuEMLbR7y56B",
    "outputId": "484e8a96-94d8-400f-b1ed-178e73b7e137"
   },
   "outputs": [],
   "source": [
    "# Carrega o dataset usando kagglehub\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"willianoliveiragibin/healthcare-insurance\",\n",
    "    \"insurance.csv\",\n",
    ")\n",
    "\n",
    "assert not df.empty, \"Dataset n√£o foi carregado corretamente\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explora√ß√£o de Dados\n",
    "\n",
    "Nesta etapa, buscamos compreender a estrutura e caracter√≠sticas principais do conjunto de dados. A an√°lise inclui:\n",
    "\n",
    "- Dimens√µes do dataset\n",
    "- Tipos de vari√°veis\n",
    "- Valores ausentes\n",
    "- Estat√≠sticas descritivas\n",
    "- Visualiza√ß√µes iniciais para facilitar a interpreta√ß√£o inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uum42cYrWQK",
    "outputId": "b80e3120-f031-4764-ed21-dfbab100408f"
   },
   "outputs": [],
   "source": [
    "# Retorna a dimensionalidade do DataFrame.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° O dataset possui 1338 linhas (registros) e 7 colunas (vari√°veis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlfB0iwy3BPH",
    "outputId": "fe7f980b-9a24-46fa-ba01-80ee1299a3f1"
   },
   "outputs": [],
   "source": [
    "# Exibe informa√ß√µes gerais do dataset: tipos de dados, contagem de valores n√£o nulos e uso de mem√≥ria.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° O dataset n√£o possui valores nulos, o que indica que ele j√° foi previamente limpo.\n",
    "\n",
    "As vari√°veis categ√≥ricas s√£o:\n",
    "\n",
    "- `sex`\n",
    "- `smoker`\n",
    "- `region`\n",
    "\n",
    "As vari√°veis num√©ricas s√£o:\n",
    "\n",
    "- `age`\n",
    "- `bmi`\n",
    "- `children`\n",
    "- `charges`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8XFY6J0iq4ab",
    "outputId": "1e8a1ea3-4a19-480c-c098-6ba73a1b8ad4"
   },
   "outputs": [],
   "source": [
    "# Visualiza as 5 primeiras linhas do dataset para inspecionar amostras reais dos dados.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "E1yGxNrMyjx-",
    "outputId": "3a8965bb-4bbc-4494-c2a0-a6eeabe363ab"
   },
   "outputs": [],
   "source": [
    "# Gera estat√≠sticas descritivas para vari√°veis num√©ricas do dataset.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A an√°lise descritiva revela informa√ß√µes importantes sobre as vari√°veis num√©ricas.\n",
    "\n",
    "Essas m√©tricas permitem avaliar a simetria, a presen√ßa de outliers e a dispers√£o das vari√°veis ‚Äî informa√ß√µes √∫teis para decis√µes de pr√©-processamento e modelagem.\n",
    "\n",
    "| **M√©trica**   | **Descri√ß√£o**                                                  | **Exemplo**                                                                            |\n",
    "| ------------- | -------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n",
    "| `count`       | N√∫mero de valores n√£o nulos na coluna.                         | Todas as colunas t√™m **1338 entradas**, indicando que o dataset est√° completo.         |\n",
    "| `mean`        | M√©dia aritm√©tica dos valores.                                  | A m√©dia de IMC (`bmi`) √© aproximadamente **30**, indicando uma tend√™ncia ao sobrepeso. |\n",
    "| `std`         | Desvio padr√£o ‚Äî indica o grau de dispers√£o em rela√ß√£o √† m√©dia. | O desvio padr√£o de `charges` √© elevado, mostrando grande varia√ß√£o nos custos m√©dicos.  |\n",
    "| `min` / `max` | Menor e maior valor observado na vari√°vel.                     | A idade (`age`) varia de **18 a 64 anos**, cobrindo uma popula√ß√£o adulta.              |\n",
    "| `25%`         | Primeiro quartil ‚Äî 25% dos dados est√£o abaixo desse valor.     | 25% dos pacientes t√™m menos de **27 anos** (`age`), indicando uma popula√ß√£o jovem.     |\n",
    "| `50%`         | Mediana ‚Äî ponto central da distribui√ß√£o.                       | A mediana de `charges` √© cerca de **9.400**, menor que a m√©dia, sugerindo assimetria.  |\n",
    "| `75%`         | Terceiro quartil ‚Äî 75% dos dados est√£o abaixo desse valor.     | 75% t√™m `charges` abaixo de **17.000**, indicando que os valores mais altos s√£o raros. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe estat√≠sticas descritivas para vari√°veis categ√≥ricas.\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As estat√≠sticas descritivas das vari√°veis categ√≥ricas revelam que:\n",
    "\n",
    "- As colunas `sex` e `smoker` s√£o bin√°rias, com apenas duas categorias distintas.\n",
    "- A coluna `region` possui 4 categorias, o que a caracteriza como categ√≥rica nominal.\n",
    "- O campo `top` indica a categoria mais comum em cada vari√°vel, e `freq` mostra sua frequ√™ncia ‚Äî √∫til para entender o balanceamento das classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lises gr√°ficas das vari√°veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "-l0km5Pls-zx",
    "outputId": "9356ee8e-25a3-4c8c-87d3-4f681f72be87"
   },
   "outputs": [],
   "source": [
    "# Cria gr√°ficos de barras para visualizar a frequ√™ncia das categorias em 'sex', 'smoker' e 'region'.\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "sns.countplot(data=df, x=\"sex\", ax=axs[0])\n",
    "axs[0].set_title(\"Distribui√ß√£o de sex\")\n",
    "\n",
    "sns.countplot(data=df, x=\"smoker\", ax=axs[1])\n",
    "axs[1].set_title(\"Distribui√ß√£o de smoker\")\n",
    "\n",
    "sns.countplot(data=df, x=\"region\", ax=axs[2])\n",
    "axs[2].set_title(\"Distribui√ß√£o de region\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A distribui√ß√£o das vari√°veis categ√≥ricas mostra que:\n",
    "\n",
    "- **`sex`**: A vari√°vel est√° aproximadamente balanceada entre masculino e feminino, o que evita vi√©s de g√™nero no treinamento do modelo.\n",
    "- **`smoker`**: A maior parte dos indiv√≠duos s√£o n√£o-fumantes, indicando desequil√≠brio de classes.\n",
    "- **`region`**: As quatro regi√µes (`northeast`, `southeast`, `southwest`, `northwest`) t√™m distribui√ß√µes similares, o que √© positivo para generaliza√ß√£o do modelo.\n",
    "\n",
    "Essas an√°lises ajudam a antecipar a necessidade de tratamento para desbalanceamentos (como em `smoker`) e a decidir o tipo de codifica√ß√£o adequada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef773fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera histogramas para visualizar a distribui√ß√£o das vari√°veis num√©ricas: age, bmi, children e charges.\n",
    "\n",
    "def plot_histogram(df, column, ax=None, kde=True):\n",
    "    sns.histplot(df[column], kde=kde, ax=ax)\n",
    "    ax.set_title(f\"Distribui√ß√£o de {column}\")\n",
    "\n",
    "cols = [\"age\", \"bmi\", \"children\", \"charges\"]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 8))\n",
    "for col, ax in zip(cols, axs.ravel()):\n",
    "    kde_flag = False if col == \"children\" else True\n",
    "    plot_histogram(df, col, ax, kde=kde_flag)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A an√°lise da distribui√ß√£o das vari√°veis num√©ricas mostra que:\n",
    "\n",
    "- **`age`**: A distribui√ß√£o √© ligeiramente assim√©trica, o que pode influenciar o modelo a focar em custos de faixas et√°rias mais jovens.\n",
    "- **`bmi`**: A distribui√ß√£o √© quase normal, mas com uma cauda √† direita, indicando alguns casos de obesidade.\n",
    "- **`children`**: A maioria dos indiv√≠duos tem 0 ou poucos filhos, com poucos casos com 4 ou mais filhos.\n",
    "- **`charges`**: A distribui√ß√£o √© muito assim√©trica e possui uma cauda longa, indicando a presen√ßa de outliers ‚Äî alguns poucos pacientes t√™m custos m√©dicos extremamente altos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera boxplots para inspecionar a distribui√ß√£o e detectar outliers nas vari√°veis num√©ricas.\n",
    "\n",
    "def plot_boxplot(df, column, ax=None):\n",
    "    sns.boxplot(x=df[column], ax=ax)\n",
    "    ax.set_title(f\"Boxplot de {column}\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 8))\n",
    "for col, ax in zip(cols, axs.ravel()):\n",
    "    plot_boxplot(df, col, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Os boxplots das vari√°veis num√©ricas revelam:\n",
    "\n",
    "- **`age`**: Distribui√ß√£o relativamente sim√©trica, sem outliers aparentes. A mediana est√° pr√≥xima ao centro da faixa et√°ria.\n",
    "- **`bmi`**: Leve assimetria √† direita e presen√ßa de alguns outliers com IMC elevado, o que pode indicar indiv√≠duos obesos.\n",
    "- **`children`**: Como vari√°vel discreta, o boxplot mostra saltos em valores fixos. N√£o h√° outliers, mas a distribui√ß√£o √© claramente enviesada para baixo.\n",
    "- **`charges`**: Forte assimetria √† direita com diversos outliers, o que confirma a cauda longa observada no histograma. Esses valores extremos podem afetar o desempenho de modelos mais sens√≠veis √† vari√¢ncia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lises gr√°ficas das correla√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria gr√°ficos de dispers√£o e stripplots para examinar rela√ß√µes com 'charges'\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "# Dispers√£o: idade vs. custo\n",
    "sns.scatterplot(data=df, x=\"age\", y=\"charges\", ax=axs[0, 0])\n",
    "axs[0, 0].set_title(\"charges vs. age\")\n",
    "\n",
    "# Dispers√£o: IMC vs. custo\n",
    "sns.scatterplot(data=df, x=\"bmi\", y=\"charges\", ax=axs[0, 1])\n",
    "axs[0, 1].set_title(\"charges vs. bmi\")\n",
    "\n",
    "# Dispers√£o: n√∫mero de filhos vs. custo\n",
    "sns.scatterplot(data=df, x=\"children\", y=\"charges\", ax=axs[1, 0])\n",
    "axs[1, 0].set_title(\"charges vs. children\")\n",
    "\n",
    "# Stripplot: fumante vs. custo\n",
    "sns.stripplot(data=df, x=\"smoker\", y=\"charges\", ax=axs[1, 1], jitter=True, alpha=0.5)\n",
    "axs[1, 1].set_title(\"charges vs. smoker\")\n",
    "\n",
    "# Stripplot: sexo vs. custo\n",
    "sns.stripplot(data=df, x=\"sex\", y=\"charges\", ax=axs[2, 0], jitter=True, alpha=0.5)\n",
    "axs[2, 0].set_title(\"charges vs. sex\")\n",
    "\n",
    "# Stripplot: regi√£o vs. custo\n",
    "sns.stripplot(data=df, x=\"region\", y=\"charges\", ax=axs[2, 1], jitter=True, alpha=0.5)\n",
    "axs[2, 1].set_title(\"charges vs. region\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Os gr√°ficos de dispers√£o e stripplots mostram padr√µes importantes entre vari√°veis explicativas e os custos m√©dicos (`charges`):\n",
    "\n",
    "- `age`: tend√™ncia de aumento nos custos com a idade, refor√ßando sua relev√¢ncia como vari√°vel cont√≠nua.\n",
    "- `bmi`: disperso, mas com ac√∫mulo de custos elevados para valores acima de 30 (obesidade).\n",
    "- `children`: pouca rela√ß√£o visual direta.\n",
    "- `smoker`: impacto evidente ‚Äî fumantes concentram-se em uma faixa muito mais alta de `charges`.\n",
    "- `sex`: pouca rela√ß√£o visual direta.\n",
    "- `region`: varia√ß√µes discretas nos custos m√©dios entre regi√µes.\n",
    "\n",
    "Essas visualiza√ß√µes refor√ßam a necessidade de considerar **efeitos n√£o lineares e intera√ß√µes entre vari√°veis**, especialmente ao escolher modelos como √°rvores de decis√£o e ensemble methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera gr√°ficos de barras para o custo m√©dico m√©dio por grupo de vari√°veis\n",
    "\n",
    "df_viz = df.copy()\n",
    "df_viz[\"age_group\"] = pd.cut(df_viz[\"age\"], bins=range(15, 70, 5))\n",
    "df_viz[\"bmi_group\"] = pd.cut(df_viz[\"bmi\"], bins=range(15, 55, 5))\n",
    "\n",
    "# Define colunas categ√≥ricas e r√≥tulos para exibi√ß√£o\n",
    "group_configs = {\n",
    "    \"age_group\": (\"Faixa et√°ria\", \"Custo m√©dio por faixa et√°ria\"),\n",
    "    \"bmi_group\": (\"Faixa de IMC\", \"Custo m√©dio por faixa de IMC\"),\n",
    "    \"children\": (\"N√∫mero de filhos\", \"Custo m√©dio por n√∫mero de filhos\"),\n",
    "    \"smoker\": (\"Fumante\", \"Custo m√©dio por tabagismo\"),\n",
    "    \"sex\": (\"Sexo\", \"Custo m√©dio por sexo\"),\n",
    "    \"region\": (\"Regi√£o\", \"Custo m√©dio por regi√£o\")\n",
    "}\n",
    "\n",
    "# Define n√∫mero de subplots dinamicamente com base na quantidade de vari√°veis\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "for ax, (col, (xlabel, title)) in zip(axs.ravel(), group_configs.items()):\n",
    "    grouped = df_viz.groupby(col)[\"charges\"].mean().reset_index()\n",
    "    sns.barplot(data=grouped, x=col, y=\"charges\", ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Custo m√©dio (USD)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A an√°lise dos custos m√©dicos m√©dios por grupos revela padr√µes claros e √∫teis para interpreta√ß√£o:\n",
    "\n",
    "- `age`: H√° um aumento progressivo no custo m√©dio conforme a faixa et√°ria avan√ßa, refletindo o aumento de risco com o envelhecimento.\n",
    "- `bmi`: A m√©dia de `charges` tende a subir a partir de IMCs acima de 30, indicando o impacto da obesidade.\n",
    "- `children`: Embora o padr√£o n√£o seja t√£o forte, h√° uma tend√™ncia leve de aumento com mais filhos.\n",
    "- `smoker`: Diferen√ßa gritante ‚Äî fumantes t√™m, em m√©dia, custos m√©dicos muito superiores aos n√£o fumantes.\n",
    "- `sex`: Pequena diferen√ßa entre os grupos, mas consistente: indiv√≠duos do sexo masculino tendem a apresentar m√©dias ligeiramente superiores.\n",
    "- `region`: As diferen√ßas entre regi√µes s√£o sutis, mas not√°veis em alguns agrupamentos ‚Äî o que pode indicar influ√™ncias geogr√°ficas nos custos.\n",
    "\n",
    "Essa visualiza√ß√£o por m√©dia facilita a comunica√ß√£o dos efeitos m√©dios das vari√°veis de forma mais acess√≠vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBsDgztf2HGq"
   },
   "source": [
    "# Pr√©-processamento de Dados\n",
    "\n",
    "Nesta etapa, realizaremos transforma√ß√µes para preparar os dados para os modelos de regress√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z0xZGgNBYTF"
   },
   "outputs": [],
   "source": [
    "# Fazemos uma c√≥pia do DataFrame original para aplicar codifica√ß√µes sem alterar os dados brutos\n",
    "df_encoded = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUt4rE-r3b4N"
   },
   "outputs": [],
   "source": [
    "# Codifica as vari√°veis bin√°rias 'sex' e 'smoker' manualmente.\n",
    "df_encoded[\"sex\"] = df_encoded[\"sex\"].map({\"female\": 0, \"male\": 1})\n",
    "df_encoded[\"smoker\"] = df_encoded[\"smoker\"].map({\"no\": 0, \"yes\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica codifica√ß√£o one-hot na vari√°vel 'region', criando colunas bin√°rias para representar cada regi√£o.\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=[\"region\"], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte colunas booleanas para inteiros (0 ou 1), garantindo compatibilidade com o modelos do statsmodels, como o OLS.\n",
    "df_encoded = df_encoded.astype({col: int for col in df_encoded.select_dtypes('bool').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "qglJ63ze-0R-",
    "outputId": "fbee5534-2d75-4530-f47c-27bb9e98a321"
   },
   "outputs": [],
   "source": [
    "# Gera um mapa de calor com a correla√ß√£o entre vari√°veis num√©ricas para identificar rela√ß√µes lineares com o custo m√©dico.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_encoded.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Mapa de Correla√ß√£o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A matriz de correla√ß√£o revela:\n",
    "\n",
    "- `smoker` tem a maior correla√ß√£o com  (0.79), indicando forte impacto nos custos m√©dicos ‚Äî possivelmente devido a maior risco associado ao tabagismo.\n",
    "- `age` possui correla√ß√£o moderada com  (0.30), o que faz sentido, j√° que idosos tendem a ter mais despesas m√©dicas.\n",
    "- `bmi` tamb√©m mostra uma correla√ß√£o positiva (0.20), o que tamb√©m faz sentido, especialmente considerando casos de obesidade.\n",
    "- `sex`, `children` e as vari√°veis de `region` t√™m correla√ß√µes fracas (pr√≥ximas de 0), sugerindo pouca influ√™ncia direta em `charges`.\n",
    "\n",
    "Essas informa√ß√µes ajudam a entender quais vari√°veis s√£o mais relevantes para o modelo e quais podem ter influ√™ncia limitada.\n",
    "\n",
    "Mesmo assim, manter as regi√µes codificadas pode ajudar modelos mais complexos a capturar intera√ß√µes n√£o-lineares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria duas vers√µes do dataset: uma para modelos lineares e outra para modelos baseados em √°rvore.\n",
    "df_tree = df_encoded.copy()\n",
    "df_linear = df_encoded.drop(columns=[\"region_southwest\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Ao aplicar one-hot encoding na vari√°vel categ√≥rica `region`, s√£o criadas m√∫ltiplas colunas bin√°ria.\n",
    "\n",
    "No entanto, manter todas essas colunas pode causar **multicolinearidade** em modelos lineares ‚Äî uma condi√ß√£o em que vari√°veis altamente correlacionadas afetam negativamente os coeficientes da regress√£o.\n",
    "\n",
    "Para evitar isso, removemos uma das colunas (no caso, `region_southwest`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza vari√°veis num√©ricas no dataset linear\n",
    "scaler = StandardScaler()\n",
    "numeric_features = [\"age\", \"bmi\", \"children\"]\n",
    "df_linear[numeric_features] = scaler.fit_transform(df_linear[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Modelos como **Regress√£o Linear**, **Ridge** e **Lasso** s√£o sens√≠veis √† escala das vari√°veis.\n",
    "\n",
    "Isso significa que atributos com valores maiores podem influenciar desproporcionalmente os coeficientes.\n",
    "\n",
    "Para evitar esse problema, utilizamos o **StandardScaler**, que transforma as vari√°veis num√©ricas (`age`, `bmi`, `children`) para uma distribui√ß√£o com m√©dia 0 e desvio padr√£o 1.  \n",
    "\n",
    "Essa padroniza√ß√£o garante que todos os atributos tenham a mesma import√¢ncia inicial no processo de ajuste dos coeficientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0_XKFqw33pL"
   },
   "source": [
    "# Modelagem\n",
    "\n",
    "Nesta etapa, definimos um dicion√°rio chamado `models` contendo os algoritmos de regress√£o que ser√£o avaliados. Cada entrada inclui:\n",
    "\n",
    "- O modelo propriamente instanciado com seus par√¢metros padr√£o (exceto o `random_state`, para garantir reprodutibilidade);\n",
    "- O conjunto de dados correspondente, preparado de forma adequada:\n",
    "  - Modelos lineares (`Linear Regression`, `Ridge`, `Lasso`) utilizam o `df_linear`, que passou por normaliza√ß√£o e ajuste de multicolinearidade;\n",
    "  - Modelos baseados em √°rvore (`Decision Tree`, `Random Forest`, `Gradient Boosting`) utilizam o `df_tree`, sem necessidade de normaliza√ß√£o.\n",
    "\n",
    "Essa separa√ß√£o permite comparar diferentes algoritmos de forma justa, utilizando os dados no formato mais apropriado para seu funcionamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"data\": df_linear\n",
    "    },\n",
    "    \"Ridge\": {\n",
    "        \"model\": Ridge(),\n",
    "        \"data\": df_linear\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"data\": df_linear\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeRegressor(random_state=42),\n",
    "        \"data\": df_tree\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        \"data\": df_tree\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"data\": df_tree\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avalia√ß√£o do Modelo\n",
    "\n",
    "Nesta etapa, treinamos os modelos para prever os custos m√©dicos com base nos dados de treino.\n",
    "Depois, avaliamos seu desempenho em dados de teste ‚Äî que os modelos ainda n√£o conheciam.\n",
    "\n",
    "Utilizamos m√©tricas como **R¬≤**, **MSE** e **RMSE** para medir a qualidade das previs√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o com Holdout (Treino/Teste)\n",
    "\n",
    "Nesta etapa, usamos a estrat√©gia **holdout** ‚Äî uma divis√£o simples dos dados em treino e teste.\n",
    "\n",
    "√â uma abordagem eficiente para avalia√ß√£o inicial, mas pode gerar resultados enviesados dependendo da divis√£o feita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJmltoQw34Jl"
   },
   "outputs": [],
   "source": [
    "results_holdout = {} # Armazena as m√©tricas por modelo\n",
    "y_preds_holdout = {} # Armazena os valores previstos por modelo\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    model = config[\"model\"]\n",
    "    df_base = config[\"data\"]\n",
    "\n",
    "    # Divide os dados em X (features) e y (target)\n",
    "    X = df_base.drop(\"charges\", axis=1)\n",
    "    y = df_base[\"charges\"]\n",
    "\n",
    "    # Divide em conjunto de treino e teste (80/20), com random_state para reprodutibilidade\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Gera predi√ß√µes para o conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcula m√©tricas de avalia√ß√£o\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Calcula RMSE manualmente (compat√≠vel com vers√µes mais antigas do sklearn)\n",
    "\n",
    "    # Salva as m√©tricas no dicion√°rio de resultados\n",
    "    results_holdout[model_name] = {\n",
    "        \"R¬≤\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "    }\n",
    "\n",
    "    # Armazena predi√ß√µes e valores reais para an√°lises gr√°ficas posteriores\n",
    "    y_preds_holdout[model_name] = y_pred\n",
    "\n",
    "df_results_holdout = (pd.DataFrame(results_holdout).T.sort_values(by=\"R¬≤\", ascending=False))\n",
    "display(df_results_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **M√©trica** | **Nome**                      | **Descri√ß√£o**                                                   | **Interpreta√ß√£o**                                 |\n",
    "| ----------- | ----------------------------- | --------------------------------------------------------------- | ------------------------------------------------- |\n",
    "| `R¬≤`        | Coeficiente de Determina√ß√£o   | Mede o quanto da varia√ß√£o em `charges` √© explicada pelo modelo. | Varia de 0 a 1. Quanto maior, melhor.             |\n",
    "| `MSE`       | Erro Quadr√°tico M√©dio         | M√©dia dos erros elevados ao quadrado.                           | Penaliza fortemente grandes erros.                |\n",
    "| `RMSE`      | Raiz do Erro Quadr√°tico M√©dio | Raiz quadrada do MSE.                                           | Tem a mesma unidade da vari√°vel alvo (`charges`). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera gr√°fico de dispers√£o: valores reais vs. previstos\n",
    "def plot_prediction_vs_actual(model_name, ax, y_true, y_pred):\n",
    "    ax.scatter(y_true, y_pred, alpha=0.5)\n",
    "    \n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Refer√™ncia (y = x)\")\n",
    "    \n",
    "    ax.set_xlabel(\"Valores Reais\")\n",
    "    ax.set_ylabel(\"Valores Previstos\")\n",
    "    ax.set_title(f\"Real vs. Previs√£o ({model_name})\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 4))\n",
    "\n",
    "plot_prediction_vs_actual(\"Linear Regression\", axs, y_test, y_preds_holdout[\"Linear Regression\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o com Valida√ß√£o Cruzada (K-Fold)\n",
    "\n",
    "Nesta etapa, avaliamos os modelos utilizando valida√ß√£o cruzada do tipo **K-Fold**, que divide os dados em 5 partes e roda m√∫ltiplas rodadas de treino e teste.\n",
    "\n",
    "Essa abordagem gera m√©tricas mais est√°veis e menos dependentes de uma √∫nica divis√£o dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define o esquema de valida√ß√£o cruzada K-Fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Dicion√°rio para armazenar os resultados\n",
    "results_table_kfold = {}\n",
    "\n",
    "# Loop por todos os modelos\n",
    "for model_name, config in models.items():\n",
    "    model = config[\"model\"]\n",
    "    df_base = config[\"data\"]\n",
    "\n",
    "    X = df_base.drop(\"charges\", axis=1)\n",
    "    y = df_base[\"charges\"]\n",
    "\n",
    "    # Realiza valida√ß√£o cruzada com m√∫ltiplas m√©tricas\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=kfold,\n",
    "        scoring={\"r2\": \"r2\", \"mse\": \"neg_mean_squared_error\"},\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Calcula as m√©tricas agregadas\n",
    "    r2_scores = cv_results[\"test_r2\"]\n",
    "    mse_scores = -cv_results[\"test_mse\"]\n",
    "    rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "    # Armazena as m√©tricas no dicion√°rio\n",
    "    results_table_kfold[model_name] = {\n",
    "        \"Mean R¬≤\": np.mean(r2_scores),\n",
    "        \"R¬≤ Std\": np.std(r2_scores),\n",
    "        \"Mean MSE\": np.mean(mse_scores),\n",
    "        \"MSE Std\": np.std(mse_scores),\n",
    "        \"Mean RMSE\": np.mean(rmse_scores),\n",
    "        \"RMSE Std\": np.std(rmse_scores),\n",
    "    }\n",
    "\n",
    "# Converte os resultados em DataFrame ordenado por desempenho\n",
    "df_results_kfold = (\n",
    "    pd.DataFrame(results_table_kfold)\n",
    "    .T\n",
    "    .sort_values(by=\"Mean R¬≤\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "df_results_kfold.rename(columns={\"index\": \"Model\"}, inplace=True)\n",
    "display(df_results_kfold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperpar√¢metros com GridSearchCV\n",
    "\n",
    "Nesta etapa, buscamos os melhores hiperpar√¢metros para cada modelo utilizando valida√ß√£o cruzada (K-Fold) e a m√©trica R¬≤ como crit√©rio de avalia√ß√£o.\n",
    "\n",
    "Isso nos permite melhorar a performance dos modelos al√©m do ajuste padr√£o, testando diferentes combina√ß√µes de par√¢metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio com modelos e respectivos grids de hiperpar√¢metros\n",
    "model_configs_grid = {\n",
    "    \"Linear Regression\": {\n",
    "        \"estimator\": models[\"Linear Regression\"][\"model\"],\n",
    "        \"param_grid\": {}\n",
    "    },\n",
    "    \"Ridge\": {\n",
    "        \"estimator\": models[\"Ridge\"][\"model\"],\n",
    "        \"param_grid\": {\n",
    "            \"alpha\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "        }\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        \"estimator\": models[\"Lasso\"][\"model\"],\n",
    "        \"param_grid\": {\n",
    "            \"alpha\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"estimator\": models[\"Decision Tree\"][\"model\"],\n",
    "        \"param_grid\": {\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 3]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"estimator\": models[\"Random Forest\"][\"model\"],\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [5, 10, None],\n",
    "            \"min_samples_leaf\": [1, 3],\n",
    "            \"max_features\": [\"sqrt\", \"log2\"]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"estimator\": models[\"Gradient Boosting\"][\"model\"],\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "            \"max_depth\": [2, 3, 4],\n",
    "            \"min_samples_leaf\": [1, 3],\n",
    "            \"subsample\": [0.8, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Avalia√ß√£o dos modelos com GridSearchCV + valida√ß√£o cruzada\n",
    "results_grid = []\n",
    "\n",
    "for model_name, config in model_configs_grid.items():\n",
    "    print(f\"Ajustando hiperpar√¢metros: {model_name}\")\n",
    "\n",
    "    # Seleciona o DataFrame correto com base no modelo\n",
    "    df_base = models[model_name][\"data\"]\n",
    "    X = df_base.drop(\"charges\", axis=1)\n",
    "    y = df_base[\"charges\"]\n",
    "\n",
    "    # Executa a busca em grade com valida√ß√£o cruzada\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config[\"estimator\"],\n",
    "        param_grid=config[\"param_grid\"],\n",
    "        scoring={\"r2\": \"r2\", \"mse\": \"neg_mean_squared_error\"},\n",
    "        refit=\"r2\",\n",
    "        cv=kfold,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Armazena os resultados principais\n",
    "    results_grid.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Best R¬≤ (CV)\": grid_search.best_score_,\n",
    "        \"Best Parameters\": grid_search.best_params_,\n",
    "        \"Best Estimator\": grid_search.best_estimator_\n",
    "    })\n",
    "\n",
    "# Cria o DataFrame ordenado por desempenho\n",
    "df_results_grid = (\n",
    "    pd.DataFrame(results_grid)\n",
    "    .sort_values(by=\"Best R¬≤ (CV)\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(df_results_grid.drop(columns=[\"Best Estimator\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valida√ß√£o Estat√≠stica\n",
    "\n",
    "Nesta se√ß√£o, realizamos uma an√°lise estat√≠stica cl√°ssica do modelo de regress√£o linear utilizando a biblioteca `statsmodels`.\n",
    "\n",
    "Diferente das abordagens anteriores, que avaliaram o desempenho preditivo dos modelos com m√©tricas como R¬≤ e RMSE, aqui o objetivo √© entender:\n",
    "- Quais vari√°veis explicativas possuem efeito estatisticamente significativo sobre os custos m√©dicos (`charges`);\n",
    "- A magnitude e dire√ß√£o desses efeitos (coeficientes);\n",
    "- A presen√ßa de multicolinearidade entre vari√°veis preditoras;\n",
    "- Se os pressupostos da regress√£o linear (normalidade dos res√≠duos, homocedasticidade, etc.) s√£o atendidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKTJ8Ri5H5h7"
   },
   "outputs": [],
   "source": [
    "# Adiciona constante para o modelo OLS (intercepto)\n",
    "X_train_sm = sm.add_constant(X_train, has_constant='add')\n",
    "X_test_sm = sm.add_constant(X_test, has_constant='add')\n",
    "\n",
    "# Converte y para float64 (recomendado para o OLS)\n",
    "y_train_sm = y_train.astype(float)\n",
    "y_test_sm = y_test.astype(float)\n",
    "\n",
    "# Treina modelo OLS com statsmodels\n",
    "ols_model = sm.OLS(y_train_sm, X_train_sm).fit()\n",
    "\n",
    "# Exibe um resumo estat√≠stico completo do model OLS (coeficientes, p-values, R¬≤ ajustado, etc.)\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Interpreta√ß√£o dos resultados do modelo OLS:\n",
    "\n",
    "* **R¬≤ = 0.742**\n",
    "  * Isso significa que o modelo consegue **explicar 74,2% da varia√ß√£o nos custos m√©dicos** com base nas vari√°veis de entrada. Ou seja, boa parte dos fatores que fazem o custo variar est√£o sendo capturados pelas vari√°veis do modelo.\n",
    "\n",
    "* **R¬≤ ajustado = 0.740**\n",
    "  * √â uma vers√£o do R¬≤ que penaliza o uso excessivo de vari√°veis. Isso evita que o modelo pare√ßa melhor s√≥ porque adicionamos mais colunas (mesmo que irrelevantes).\n",
    "  * O fato de estar muito pr√≥ximo do R¬≤ comum indica que as vari√°veis adicionadas realmente ajudam a explicar o custo ‚Äî n√£o est√£o apenas ‚Äúinflando‚Äù a performance do modelo artificialmente.\n",
    "\n",
    "* **F-statistic = 380.9 (p < 0.001)**\n",
    "  * Esse teste verifica se o modelo, como um todo, √© melhor do que simplesmente chutar a m√©dia para todos os casos.\n",
    "  * O valor de **p < 0.001** indica que a chance de o modelo ser ruim por acaso √© **menor que 0.1%** ‚Äî o que √© considerado altamente significativo em estat√≠stica.\n",
    "  * Portanto, temos evid√™ncia forte de que o conjunto de vari√°veis realmente ajuda a prever os custos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Vari√°vel          | Coef.   | P-valor | Significativo? | Interpreta√ß√£o                                                           |\n",
    "| ----------------- | ------- | ------- | -------------- | ----------------------------------------------------------------------- |\n",
    "| **age**           | +256.98 | <0.001  | ‚úÖ              | Cada ano a mais aumenta o custo m√©dio em \\~R\\$257.                     |\n",
    "| **sex**           | -18.59  | 0.961   | ‚ùå              | Sem efeito significativo entre homens/mulheres.                        |\n",
    "| **bmi**           | +337.09 | <0.001  | ‚úÖ              | Cada ponto extra no IMC aumenta os custos em \\~R\\$337.                 |\n",
    "| **children**      | +425.28 | 0.006   | ‚úÖ              | Cada filho a mais aumenta o custo m√©dio em \\~R\\$425.                   |\n",
    "| **smoker**        | +23.657 | <0.001  | ‚úÖ              | Fumantes t√™m em m√©dia R\\$23.657 a mais em custos.                      |\n",
    "| region\\_northeast | +657.86 | 0.223   | ‚ùå              | N√£o tem impacto significativo.                                         |\n",
    "| region\\_northwest | +287.19 | 0.598   | ‚ùå              | N√£o tem impacto significativo.                                         |\n",
    "| region\\_southwest | -151.94 | 0.775   | ‚ùå              | N√£o tem impacto significativo.                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- ### üß™ **Resumo das vari√°veis significativas**\n",
    "\n",
    "* ‚úÖ **`smoker`** √© de longe a vari√°vel com **maior impacto e signific√¢ncia**.\n",
    "* ‚úÖ **`age`**, **`bmi`** e **`children`** tamb√©m s√£o estatisticamente significativas.\n",
    "* ‚ùå **`sex`** e **`region_*`** **n√£o t√™m efeito significativo** ‚Äî ou seja, n√£o explicam varia√ß√µes relevantes nos custos m√©dicos nesse modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Considera√ß√µes finais\n",
    "\n",
    "* A estrutura do modelo √© robusta, com boa explica√ß√£o da variabilidade de `charges`.\n",
    "* **N√£o h√° multicolinearidade perfeita**, dado que o modelo foi ajustado com One-Hot Encoding (removendo uma dummy).\n",
    "* A aus√™ncia de signific√¢ncia de algumas vari√°veis pode indicar que elas:\n",
    "\n",
    "  * N√£o afetam diretamente os custos m√©dicos\n",
    "  * T√™m efeito indireto j√° absorvido por outras vari√°veis (como `smoker` ou `bmi`)\n",
    "* Voc√™ poderia optar por **remover vari√°veis com p > 0.05** para simplificar o modelo sem perda de desempenho.\n",
    "\n",
    "---\n",
    "\n",
    "Se quiser, posso gerar um gr√°fico com os coeficientes significativos ou auxiliar na simplifica√ß√£o do modelo OLS. Deseja isso? -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21Pn1av0xgHW"
   },
   "source": [
    "# Conclus√£o\n",
    "\n",
    "Este notebook teve como objetivo prever os custos m√©dicos individuais (`charges`) com base em dados demogr√°ficos e comportamentais simulados, como idade, IMC, n√∫mero de filhos, tabagismo e regi√£o. E encontramos os seguintes insights:\n",
    "\n",
    "- A vari√°vel **`smoker`** apresentou o maior impacto nos custos, com efeito estimado entre R$ 22.735 e R$ 24.566.\n",
    "- Os modelos lineares explicaram cerca de **74% da varia√ß√£o** em `charges`, enquanto o **Random Forest** atingiu **86%**, com menor erro m√©dio (RMSE).\n",
    "- Vari√°veis como **`sex`** e **`region`** n√£o apresentaram efeito significativo isoladamente.\n",
    "- A an√°lise estat√≠stica com OLS forneceu maior interpretabilidade, enquanto o Random Forest teve melhor desempenho preditivo.\n",
    "- O modelo Random Forest foi o que melhor capturou os padr√µes dos dados, sendo a escolha mais adequada para aplica√ß√µes com foco em precis√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Final\n",
    "\n",
    "Ap√≥s a valida√ß√£o cruzada e a busca em grade por hiperpar√¢metros ideais, identificamos que o modelo com melhor desempenho foi o **Gradient Boosting Regressor**.\n",
    "\n",
    "Para consolidar esse modelo em um fluxo reprodut√≠vel e escal√°vel, constru√≠mos uma pipeline completa.\n",
    "Esta pipeline realiza o pr√©-processamento dos dados e aplica o modelo treinado de forma integrada.\n",
    "\n",
    "- **Codifica√ß√£o ordinal** para vari√°veis bin√°rias (`sex`, `smoker`);\n",
    "- **One-hot encoding** para a vari√°vel categ√≥rica `region` (com exclus√£o da primeira categoria para evitar multicolinearidade);\n",
    "- **Passagem direta** das vari√°veis num√©ricas (`age`, `bmi`, `children`);\n",
    "- **Treinamento e predi√ß√£o** com o `GradientBoostingRegressor`, configurado com os melhores hiperpar√¢metros obtidos via GridSearchCV.\n",
    "\n",
    "Essa abordagem permite encapsular todo o processo de prepara√ß√£o e modelagem em um √∫nico objeto, facilitando tanto a manuten√ß√£o quanto a aplica√ß√£o do modelo em novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o das colunas\n",
    "numeric_features = ['age', 'bmi', 'children']\n",
    "binary_features = ['sex', 'smoker']\n",
    "categorical_features = ['region']\n",
    "\n",
    "# Pr√©-processador\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('encode_binary', OrdinalEncoder(dtype=int), binary_features),\n",
    "    ('encode_categorical', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('pass_numeric', 'passthrough', numeric_features)\n",
    "])\n",
    "\n",
    "# Pipeline final com o melhor modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=1,\n",
    "        subsample=1.0,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Divis√£o dos dados\n",
    "X = df.drop(columns=['charges'])\n",
    "y = df['charges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o pipeline treinado em um arquivo usando joblib\n",
    "joblib.dump(pipeline, 'gradient_boosting_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega e usa o pipeline treinado do arquivo\n",
    "pipeline_loaded = joblib.load('gradient_boosting_pipeline.pkl')\n",
    "\n",
    "y_pred = pipeline_loaded.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'R¬≤: {r2:.4f}')\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
